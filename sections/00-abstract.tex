While camera-based systems are the dominant approach for human pose estimation, they face challenges regarding privacy concerns and occlusion problems. 
To assess an alternative to camera-based pose estimation, this paper aims to predict 3D walking poses using SensFloor: a capacitance-based floor that registers movement activity. We analyze the potential of utilizing the floor's low-resolution signals to estimate poses and to what extent certain joint positions can be predicted. For this purpose, we collected synchronized SensFloor signals and video data, from which we extracted 3D human poses using MediaPipe to serve as ground-truth targets for training. These signals and their corresponding targets were then used for supervised training of an LSTM neural network. To estimate a person's position on the floor, we applied a clustering approach followed by a Kalman filter to smooth the trajectory. Our results demonstrate that it is possible to predict simple human walking poses using the proposed methods, establishing a proof-of-concept for an alternative way of activity monitoring.