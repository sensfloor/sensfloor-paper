@article{avogaro2023markerlesshumanpose,
  title = {Markerless Human Pose Estimation for Biomedical Applications: A Survey},
  author = {Avogaro, Andrea and Cunico, Federico and Rosenhahn, Bodo and Setti, Francesco},
  date = {2023-07-06},
  journaltitle = {Frontiers in Computer Science},
  volume = {5},
  doi = {10.3389/fcomp.2023.1153160},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/V5F68MR5/Avogaro et al. - 2023 - Markerless human pose estimation for biomedical applications a survey.pdf}
}

@online{bazarevsky2020blazeposeondevicerealtime,
  title = {{{BlazePose}}: {{On-device Real-time Body Pose}} Tracking},
  author = {Bazarevsky, Valentin and Grishchenko, Ivan and Raveendran, Karthik and Zhu, Tyler and Zhang, Fan and Grundmann, Matthias},
  date = {2020-06-17},
  doi = {10.48550/arXiv.2006.10204},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/felixbauer/Zotero/storage/9PKQ9VP9/Bazarevsky et al. - 2020 - BlazePose On-device Real-time Body Pose tracking.pdf}
}

@article{hoffmann2018estimatingpersonsage,
  title = {Estimating a Person's Age from Walking over a Sensor Floor},
  author = {Hoffmann, Raoul and Lauterbach, Christl and Conradt, Jörg and Steinhage, Axel},
  date = {2018-04-01},
  journaltitle = {Computers in Biology and Medicine},
  volume = {95},
  pages = {271--276},
  doi = {10.1016/j.compbiomed.2017.11.003},
  langid = {english},
  keywords = {Age estimation,Gait analysis,Machine learning,Multi-layer perceptron,Neural network,Sensor floor},
  file = {/Users/felixbauer/Zotero/storage/CSKJCKV9/Hoffmann et al. - 2018 - Estimating a person's age from walking over a sens.pdf}
}

@article{hoffmann2021detectingwalkingchallenges,
  title = {Detecting {{Walking Challenges}} in {{Gait Patterns Using}} a {{Capacitive Sensor Floor}} and {{Recurrent Neural Networks}}},
  author = {Hoffmann, Raoul and Brodowski, Hanna and Steinhage, Axel and Grzegorzek, Marcin},
  date = {2021-02-05},
  journaltitle = {Sensors},
  volume = {21},
  number = {4},
  pages = {1086},
  doi = {10.3390/s21041086},
  abstract = {Gait patterns are a result of the complex kinematics that enable human two-legged locomotion, and they can reveal a lot about a person’s state and health. Analysing them is useful for researchers to get new insights into the course of diseases, and for physicians to track the progress after healing from injuries. When a person walks and is interfered with in any way, the resulting disturbance can show up and be found in the gait patterns. This paper describes an experimental setup for capturing gait patterns with a capacitive sensor floor, which can detect the time and position of foot contacts on the floor. With this setup, a dataset was recorded where 42 participants walked over a sensor floor in different modes, inter alia, normal pace, closed eyes, and dual-task. A recurrent neural network based on Long Short-Term Memory units was trained and evaluated for the classification task of recognising the walking mode solely from the floor sensor data. Furthermore, participants were asked to do the Unilateral Heel-Rise Test, and their gait was recorded before and after doing the test. Another neural network instance was trained to predict the number of repetitions participants were able to do on the test. As the results of the classification tasks turned out to be promising, the combination of this sensor floor and the recurrent neural network architecture seems like a good system for further investigation leading to applications in health and care.},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/7II2RGLM/Hoffmann et al. - 2021 - Detecting Walking Challenges in Gait Patterns Using a Capacitive Sensor Floor and Recurrent Neural N.pdf}
}

@incollection{lauterbach2013largeareasensorsystem,
  title = {A {{Large-Area Sensor System Underneath}} the {{Floor}} for {{Ambient Assisted Living Applications}}},
  booktitle = {Pervasive and {{Mobile Sensing}} and {{Computing}} for {{Healthcare}}},
  author = {Lauterbach, C. and Steinhage, A. and Techmer, A.},
  editor = {Mukhopadhyay, Subhas Chandra and Postolache, Octavian A.},
  date = {2013},
  volume = {2},
  pages = {69--87},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-32538-0_3},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/6W3UD4Z3/Lauterbach et al. - 2013 - A Large-Area Sensor System Underneath the Floor for Ambient Assisted Living Applications.pdf}
}

@inproceedings{luo2021intelligentcarpetinferring,
  title = {Intelligent {{Carpet}}: {{Inferring 3D Human Pose}} from {{Tactile Signals}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Luo, Yiyue and Li, Yunzhu and Foshey, Michael and Shou, Wan and Sharma, Pratyusha and Palacios, Tomas and Torralba, Antonio and Matusik, Wojciech},
  date = {2021-06},
  pages = {11250--11260},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.01110},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/DXFVI4ZH/Luo et al. - 2021 - Intelligent Carpet Inferring 3D Human Pose from T.pdf}
}

@article{rogerr.2024kalmanbayesianfilters,
  title = {Kalman and {{Bayesian Filters}} in {{Python}}},
  author = {{Roger R.} and {Labbe}},
  date = {2024},
  url = {https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/PJNK993R/Jr - Kalman and Bayesian Filters in Python.pdf}
}

@inproceedings{sousa2013humantrackingidentification,
  title = {Human Tracking and Identification Using a Sensitive Floor and Wearable Accelerometers},
  booktitle = {2013 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}})},
  author = {Sousa, M. and Techmer, A. and Steinhage, A. and Lauterbach, C. and Lukowicz, P.},
  date = {2013-03},
  pages = {166--171},
  publisher = {IEEE},
  location = {San Diego, CA},
  doi = {10.1109/PerCom.2013.6526728},
  eventtitle = {2013 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}} 2013)},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/X9N3RIN6/Sousa et al. - 2013 - Human tracking and identification using a sensitive floor and wearable accelerometers.pdf}
}

@online{watanabe2025p2pinsolehumanpose,
  title = {{{P2P-Insole}}: {{Human Pose Estimation Using Foot Pressure Distribution}} and {{Motion Sensors}}},
  author = {Watanabe, Atsuya and Aisuwarya, Ratna and Jing, Lei},
  date = {2025-05-01},
  doi = {10.48550/arXiv.2505.00755},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/felixbauer/Zotero/storage/SDWAWDDJ/Watanabe et al. - 2025 - P2P-Insole Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors.pdf}
}

@article{zheng2023deeplearningbasedhuman,
  title = {Deep {{Learning-based Human Pose Estimation}}: {{A Survey}}},
  author = {Zheng, Ce and Wu, Wenhan and Chen, Chen and Yang, Taojiannan and Zhu, Sijie and Shen, Ju and Kehtarnavaz, Nasser and Shah, Mubarak},
  date = {2023-08-26},
  journaltitle = {ACM Computing Surveys},
  volume = {56},
  number = {1},
  pages = {1--37},
  doi = {10.1145/3603618},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/KJCGQUWU/Zheng et al. - 2023 - Deep Learning-based Human Pose Estimation A Survey.pdf}
}
