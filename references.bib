@article{avogaro2023markerlesshumanpose,
  title = {Markerless Human Pose Estimation for Biomedical Applications: A Survey},
  shorttitle = {Markerless Human Pose Estimation for Biomedical Applications},
  author = {Avogaro, Andrea and Cunico, Federico and Rosenhahn, Bodo and Setti, Francesco},
  date = {2023-07-06},
  journaltitle = {Frontiers in Computer Science},
  shortjournal = {Front. Comput. Sci.},
  volume = {5},
  pages = {1153160},
  issn = {2624-9898},
  doi = {10.3389/fcomp.2023.1153160},
  url = {https://www.frontiersin.org/articles/10.3389/fcomp.2023.1153160/full},
  urldate = {2026-02-14},
  abstract = {Markerless Human Pose Estimation (HPE) proved its potential to support decision making and assessment in many fields of application. HPE is often preferred to traditional marker-based Motion Capture systems due to the ease of setup, portability, and affordable cost of the technology. However, the exploitation of HPE in biomedical applications is still under investigation. This review aims to provide an overview of current biomedical applications of HPE. In this paper, we examine the main features of HPE approaches and discuss whether or not those features are of interest to biomedical applications. We also identify those areas where HPE is already in use and present peculiarities and trends followed by researchers and practitioners. We include here 25 approaches to HPE and more than 40 studies of HPE applied to motor development assessment, neuromuscolar rehabilitation, and gait \&amp; posture analysis. We conclude that markerless HPE offers great potential for extending diagnosis and rehabilitation outside hospitals and clinics, toward the paradigm of               remote medical care               .},
  file = {/Users/felixbauer/Zotero/storage/V5F68MR5/Avogaro et al. - 2023 - Markerless human pose estimation for biomedical applications a survey.pdf}
}

@online{bazarevsky2020blazeposeondevicerealtime,
  title = {{{BlazePose}}: {{On-device Real-time Body Pose}} Tracking},
  shorttitle = {{{BlazePose}}},
  author = {Bazarevsky, Valentin and Grishchenko, Ivan and Raveendran, Karthik and Zhu, Tyler and Zhang, Fan and Grundmann, Matthias},
  date = {2020-06-17},
  eprint = {2006.10204},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2006.10204},
  url = {http://arxiv.org/abs/2006.10204},
  urldate = {2026-02-08},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/felixbauer/Zotero/storage/9PKQ9VP9/Bazarevsky et al. - 2020 - BlazePose On-device Real-time Body Pose tracking.pdf}
}

@article{faulkner2020caploccapacitivesensing,
  title = {{{CapLoc}}: {{Capacitive Sensing Floor}} for {{Device-Free Localization}} and {{Fall Detection}}},
  shorttitle = {{{CapLoc}}},
  author = {Faulkner, Nathaniel and Parr, Baden and Alam, Fakhrul and Legg, Mathew and Demidenko, Serge},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {187353--187364},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3029971},
  url = {https://ieeexplore.ieee.org/document/9220093/},
  urldate = {2025-10-31},
  file = {/Users/felixbauer/Zotero/storage/8ZW6JK7M/Faulkner et al. - 2020 - CapLoc Capacitive Sensing Floor for Device-Free Localization and Fall Detection.pdf}
}

@article{hoffmann2018estimatingpersonsage,
  title = {Estimating a Person's Age from Walking over a Sensor Floor},
  author = {Hoffmann, Raoul and Lauterbach, Christl and Conradt, Jörg and Steinhage, Axel},
  date = {2018-04-01},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {95},
  pages = {271--276},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2017.11.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482517303633},
  urldate = {2025-05-13},
  abstract = {Ageing has an effect on many parameters of the physical condition, and one of them is the way a person walks. This property, the gait pattern, can unintrusively be observed by letting people walk over a sensor floor. The electric capacitance sensors built into the floor deliver information about when and where feet get into close proximity and contact with the floor during the phases of human locomotion. We processed gait patterns recorded this way by extracting a feature vector containing the discretised distribution of occurring geometrical extents of significant sensor readings. This kind of feature vector is an implicit measure encoding the ratio of swing-to stance phase timings in the gait cycle and representing how cleanly the leg swing is performed. We then used the dataset to train a Multi-Layer Perceptron to perform regression with the age of the person as the target value, and the feature vector as input. With this method and a dataset size of 142 persons recorded, we achieved a mean absolute error of approximately 10 years between the true age and the estimated age of the person. Considering the novelty of our approach, this is an acceptable result. The combination of a floor sensor and machine learning methods for interpreting the sensor data seems promising for further research and applications in care and medicine.},
  keywords = {Age estimation,Gait analysis,Machine learning,Multi-layer perceptron,Neural network,Sensor floor},
  file = {/Users/felixbauer/Zotero/storage/CSKJCKV9/Hoffmann et al. - 2018 - Estimating a person's age from walking over a sens.pdf}
}

@article{hoffmann2021detectingwalkingchallenges,
  title = {Detecting {{Walking Challenges}} in {{Gait Patterns Using}} a {{Capacitive Sensor Floor}} and {{Recurrent Neural Networks}}},
  author = {Hoffmann, Raoul and Brodowski, Hanna and Steinhage, Axel and Grzegorzek, Marcin},
  date = {2021-02-05},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {21},
  number = {4},
  pages = {1086},
  issn = {1424-8220},
  doi = {10.3390/s21041086},
  url = {https://www.mdpi.com/1424-8220/21/4/1086},
  urldate = {2025-10-22},
  abstract = {Gait patterns are a result of the complex kinematics that enable human two-legged locomotion, and they can reveal a lot about a person’s state and health. Analysing them is useful for researchers to get new insights into the course of diseases, and for physicians to track the progress after healing from injuries. When a person walks and is interfered with in any way, the resulting disturbance can show up and be found in the gait patterns. This paper describes an experimental setup for capturing gait patterns with a capacitive sensor floor, which can detect the time and position of foot contacts on the floor. With this setup, a dataset was recorded where 42 participants walked over a sensor floor in different modes, inter alia, normal pace, closed eyes, and dual-task. A recurrent neural network based on Long Short-Term Memory units was trained and evaluated for the classification task of recognising the walking mode solely from the floor sensor data. Furthermore, participants were asked to do the Unilateral Heel-Rise Test, and their gait was recorded before and after doing the test. Another neural network instance was trained to predict the number of repetitions participants were able to do on the test. As the results of the classification tasks turned out to be promising, the combination of this sensor floor and the recurrent neural network architecture seems like a good system for further investigation leading to applications in health and care.},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/7II2RGLM/Hoffmann et al. - 2021 - Detecting Walking Challenges in Gait Patterns Using a Capacitive Sensor Floor and Recurrent Neural N.pdf}
}

@incollection{lauterbach2013largeareasensorsystema,
  title = {A {{Large-Area Sensor System Underneath}} the {{Floor}} for {{Ambient Assisted Living Applications}}},
  booktitle = {Pervasive and {{Mobile Sensing}} and {{Computing}} for {{Healthcare}}},
  author = {Lauterbach, C. and Steinhage, A. and Techmer, A.},
  editor = {Mukhopadhyay, Subhas Chandra and Postolache, Octavian A.},
  date = {2013},
  volume = {2},
  pages = {69--87},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-32538-0_3},
  url = {https://link.springer.com/10.1007/978-3-642-32538-0_3},
  urldate = {2025-11-11},
  abstract = {The SensFloor® is a textile-based large-area sensor system which is installed as an underlay underneath the flooring. It detects people moving across the floor, calculates their trajectories and distinguishes between foot steps and a fall. The use of capacitive proximity sensing instead of pressure sensing gives high flexibility in floor design. Besides elastic flooring like carpet and PVC, even non-elastic flooring like parquet or laminate is suitable. The SensFloor System enables a variety of different applications in the domain of Ambient Assisted Living (AAL) like fall detection, activity monitoring, energy savings, control of automatic doors, intrusion alarm and access control. Presence detection and self-test capabilities are additional features valuable in particular for security applications.},
  isbn = {978-3-642-32537-3 978-3-642-32538-0},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/6W3UD4Z3/Lauterbach et al. - 2013 - A Large-Area Sensor System Underneath the Floor for Ambient Assisted Living Applications.pdf}
}

@inproceedings{luo2021intelligentcarpetinferring,
  title = {Intelligent {{Carpet}}: {{Inferring 3D Human Pose}} from {{Tactile Signals}}},
  shorttitle = {Intelligent {{Carpet}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Luo, Yiyue and Li, Yunzhu and Foshey, Michael and Shou, Wan and Sharma, Pratyusha and Palacios, Tomas and Torralba, Antonio and Matusik, Wojciech},
  date = {2021-06},
  pages = {11250--11260},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.01110},
  url = {https://ieeexplore.ieee.org/document/9577856/},
  urldate = {2025-05-13},
  abstract = {Daily human activities, e.g., locomotion, exercises, and resting, are heavily guided by the tactile interactions between the human and the ground. In this work, leveraging such tactile interactions, we propose a 3D human pose estimation approach using the pressure maps recorded by a tactile carpet as input. We build a low-cost, high-density, large-scale intelligent carpet, which enables the real-time recordings of human-floor tactile interactions in a seamless manner. We collect a synchronized tactile and visual dataset on various human activities. Employing a state-ofthe-art camera-based pose estimation model as supervision, we design and implement a deep neural network model to infer 3D human poses using only the tactile information. Our pipeline can be further scaled up to multi-person pose estimation. We evaluate our system and demonstrate its potential applications in diverse fields.},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-6654-4509-2},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/DXFVI4ZH/Luo et al. - 2021 - Intelligent Carpet Inferring 3D Human Pose from T.pdf}
}

@article{rogerr.2024kalmanbayesianfilters,
  title = {Kalman and {{Bayesian Filters}} in {{Python}}},
  author = {{Roger R.} and {Labbe}},
  date = {2024},
  url = {https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python},
  langid = {english},
  file = {/Users/felixbauer/Zotero/storage/PJNK993R/Jr - Kalman and Bayesian Filters in Python.pdf}
}

@inproceedings{sousa2013humantrackingidentification,
  title = {Human Tracking and Identification Using a Sensitive Floor and Wearable Accelerometers},
  booktitle = {2013 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}})},
  author = {Sousa, M. and Techmer, A. and Steinhage, A. and Lauterbach, C. and Lukowicz, P.},
  date = {2013-03},
  pages = {166--171},
  publisher = {IEEE},
  location = {San Diego, CA},
  doi = {10.1109/PerCom.2013.6526728},
  url = {http://ieeexplore.ieee.org/document/6526728/},
  urldate = {2025-10-31},
  eventtitle = {2013 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}} ({{PerCom}} 2013)},
  isbn = {978-1-4673-4575-0 978-1-4673-4573-6 978-1-4673-4574-3},
  file = {/Users/felixbauer/Zotero/storage/X9N3RIN6/Sousa et al. - 2013 - Human tracking and identification using a sensitive floor and wearable accelerometers.pdf}
}

@online{watanabe2025p2pinsolehumanpose,
  title = {{{P2P-Insole}}: {{Human Pose Estimation Using Foot Pressure Distribution}} and {{Motion Sensors}}},
  shorttitle = {{{P2P-Insole}}},
  author = {Watanabe, Atsuya and Aisuwarya, Ratna and Jing, Lei},
  date = {2025-05-01},
  eprint = {2505.00755},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2505.00755},
  url = {http://arxiv.org/abs/2505.00755},
  urldate = {2025-11-03},
  abstract = {This work presents P2P-Insole, a low-cost approach for estimating and visualizing 3D human skeletal data using insole-type sensors integrated with IMUs. Each insole, fabricated with e-textile garment techniques, costs under USD 1, making it significantly cheaper than commercial alternatives and ideal for large-scale production. Our approach uses foot pressure distribution, acceleration, and rotation data to overcome limitations, providing a lightweight, minimally intrusive, and privacy-aware solution. The system employs a Transformer model for efficient temporal feature extraction, enriched by first and second derivatives in the input stream. Including multimodal information, such as accelerometers and rotational measurements, improves the accuracy of complex motion pattern recognition. These facts are demonstrated experimentally, while error metrics show the robustness of the approach in various posture estimation tasks. This work could be the foundation for a low-cost, practical application in rehabilitation, injury prevention, and health monitoring while enabling further development through sensor optimization and expanded datasets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/felixbauer/Zotero/storage/SDWAWDDJ/Watanabe et al. - 2025 - P2P-Insole Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors.pdf}
}

@article{zheng2023deeplearningbasedhuman,
  title = {Deep {{Learning-based Human Pose Estimation}}: {{A Survey}}},
  shorttitle = {Deep {{Learning-based Human Pose Estimation}}},
  author = {Zheng, Ce and Wu, Wenhan and Chen, Chen and Yang, Taojiannan and Zhu, Sijie and Shen, Ju and Kehtarnavaz, Nasser and Shah, Mubarak},
  date = {2023-08-26},
  journaltitle = {ACM Comput. Surv.},
  volume = {56},
  number = {1},
  pages = {11:1--11:37},
  issn = {0360-0300},
  doi = {10.1145/3603618},
  url = {https://dl.acm.org/doi/10.1145/3603618},
  urldate = {2026-02-13},
  abstract = {Human pose estimation aims to locate the human body parts and build human body representation (e.g., body skeleton) from input data such as images and videos. It has drawn increasing attention during the past decade and has been utilized in a wide range of applications including human-computer interaction, motion analysis, augmented reality, and virtual reality. Although the recently developed deep learning-based solutions have achieved high performance in human pose estimation, there still remain challenges due to insufficient training data, depth ambiguities, and occlusion. The goal of this survey article is to provide a comprehensive review of recent deep learning-based solutions for both 2D and 3D pose estimation via a systematic analysis and comparison of these solutions based on their input data and inference procedures. More than 260 research papers since 2014 are covered in this survey. Furthermore, 2D and 3D human pose estimation datasets and evaluation metrics are included. Quantitative performance comparisons of the reviewed methods on popular datasets are summarized and discussed. Finally, the challenges involved, applications, and future research directions are concluded. A regularly updated project page is provided: .},
  file = {/Users/felixbauer/Zotero/storage/KJCGQUWU/Zheng et al. - 2023 - Deep Learning-based Human Pose Estimation A Survey.pdf}
}
